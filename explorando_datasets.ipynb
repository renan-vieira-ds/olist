{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f32d7e6-1665-4653-ba6f-a65c80731f88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Imports e Leitura do Dicionáŕio de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c89497-1270-4886-8055-5498cbbf7c4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import json\n",
    "import urllib.request\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26f486f1-6edf-4a72-8ba3-f3bf082c5fbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dicionario = pd.read_csv('artifacts/dicionario.csv')\n",
    "dicionario = dicionario[(dicionario.tabela != 'geolocation') & (dicionario.tabela != 'product_category_name_translation')]\n",
    "display(dicionario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a767cc6-8d8f-44cd-a939-df7c55068197",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Análise geral - granularidade da Olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ceefb83-6be6-481c-842e-21c5a726ac94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "vendas_totais = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  DATE_TRUNC('month', o.order_purchase_timestamp) AS safra,\n",
    "  COUNT(DISTINCT oi.order_id) AS total_pedidos,\n",
    "  SUM(oi.price) AS total_valor\n",
    "FROM \n",
    "  olist.default.order_items oi\n",
    "JOIN \n",
    "  olist.default.orders o\n",
    "ON \n",
    "  oi.order_id = o.order_id\n",
    "WHERE \n",
    "  o.order_status = 'delivered'\n",
    "GROUP BY \n",
    "  DATE_TRUNC('month', o.order_purchase_timestamp)\n",
    "ORDER BY \n",
    "  safra\n",
    "\"\"\").toPandas()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Safra (mês)')\n",
    "ax1.set_ylabel('Total de pedidos', color=color)\n",
    "line1, = ax1.plot(vendas_totais['safra'], vendas_totais['total_pedidos'], color=color, marker='o', label='Qtd Pedidos')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Compartilhando eixo x\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('Valor total vendido (R$)', color=color)\n",
    "line2, = ax2.plot(vendas_totais['safra'], vendas_totais['total_valor'], color=color, marker='s', linestyle='--', label='Valor Total')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Total de pedidos e valor vendido por safra (todos os sellers)')\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "fig.tight_layout()\n",
    "plt.grid()\n",
    "\n",
    "lines = [line1, line2]\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e357143b-22bf-4ffa-8b3c-4bc3e491de88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        DATE_TRUNC('month', o.order_purchase_timestamp) AS safra,\n",
    "        AVG(r.review_score) AS nota_media\n",
    "    FROM olist.default.orders o\n",
    "    JOIN olist.default.order_reviews r\n",
    "    ON o.order_id = r.order_id\n",
    "    GROUP BY safra\n",
    "    ORDER BY safra\n",
    "\"\"\").toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df['safra'], df['nota_media'], marker='o', color='orange')\n",
    "plt.title(\"Nota média de reviews por safra\")\n",
    "plt.ylabel(\"Nota média\")\n",
    "plt.xlabel(\"Safra (mês)\")\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3baa6fa8-ab33-4951-a2e3-da123e25d94c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\" \n",
    "        SELECT \n",
    "            DATE_TRUNC('month', o.order_purchase_timestamp) AS safra,\n",
    "            AVG(oi.price) AS ticket_medio\n",
    "        FROM olist.default.orders o\n",
    "        JOIN olist.default.order_items oi ON o.order_id = oi.order_id\n",
    "        WHERE o.order_status = 'delivered'\n",
    "        GROUP BY safra\n",
    "        ORDER BY safra\n",
    " \"\"\").toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df['safra'], df['ticket_medio'], marker='d', color='orange')\n",
    "plt.title(\"Ticket médio por safra\")\n",
    "plt.ylabel(\"R$ ticket médio\")\n",
    "plt.xlabel(\"Safra (mês)\")\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee16dc7f-5f3f-4c12-a086-ddbf8d3b036c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Y esquerdo\n",
    "color1 = 'tab:blue'\n",
    "ax1.set_xlabel('Safra (mês)')\n",
    "ax1.set_ylabel('Ticket Médido (R$)', color=color1)\n",
    "line1, = ax1.plot(df['safra'], df['ticket_medio'], color=color1, marker='o', label='Ticket  Médio')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Y direito\n",
    "ax2 = ax1.twinx()\n",
    "color2 = 'tab:green'\n",
    "ax2.set_ylabel('Total de Pedidos', color=color2)\n",
    "line2, = ax2.plot(df['safra'], df['total_pedidos'], color=color2, marker='s', linestyle='--', label='Pedidos')\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "fig.suptitle('Ticket Médio e Pedidos por safra')\n",
    "fig.autofmt_xdate()\n",
    "fig.tight_layout()\n",
    "ax1.legend(\n",
    "    [line1, line2], \n",
    "    [line.get_label() for line in [line1, line2]], \n",
    "    loc='lower right'\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16e5ae84-1d6e-4596-9c3a-bc728e4b4262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\" \n",
    "        SELECT \n",
    "            DATE_TRUNC('month', order_purchase_timestamp) AS safra,\n",
    "            COUNT(*) AS total_entregas,\n",
    "            SUM(CASE WHEN order_delivered_customer_date > order_estimated_delivery_date THEN 1 ELSE 0 END) AS atrasadas,\n",
    "            100.0 * SUM(CASE WHEN order_delivered_customer_date > order_estimated_delivery_date THEN 1 ELSE 0 END) / COUNT(*) AS perc_atrasadas\n",
    "        FROM olist.default.orders\n",
    "        WHERE order_status != 'canceled' OR order_status != 'unavailable'\n",
    "        GROUP BY safra\n",
    "        ORDER BY safra\n",
    " \"\"\").toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df['safra'], df['perc_atrasadas'], marker='s', color='orange')\n",
    "plt.title(\"Percentual de entregas atrasadas por safra\")\n",
    "plt.ylabel(\"% atrasadas\")\n",
    "plt.xlabel(\"Safra (mês)\")\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c97af2b0-967e-4687-9f1c-7f49b9960571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_tempo_entrega = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  DATEDIFF(order_delivered_customer_date, order_purchase_timestamp) AS dias_entrega\n",
    "FROM olist.default.orders\n",
    "WHERE order_status = 'delivered'\n",
    "  AND order_delivered_customer_date IS NOT NULL\n",
    "  AND order_purchase_timestamp IS NOT NULL\n",
    "\"\"\").toPandas()\n",
    "\n",
    "# Filtrar outliers\n",
    "df_plot = df_tempo_entrega[df_tempo_entrega['dias_entrega'].between(0, 60)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(df_plot['dias_entrega'], bins=30, color='mediumslateblue', edgecolor='black')\n",
    "plt.title(\"Distribuição do tempo de entrega (em dias)\")\n",
    "plt.xlabel(\"Dias entre compra e entrega\")\n",
    "plt.ylabel(\"Frequência de pedidos\")\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "643582e3-c46a-4616-a00b-2ac705b37d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_safra_avaliacoes = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  DATE_TRUNC('month', o.order_purchase_timestamp) AS safra,\n",
    "  AVG(r.review_score) AS nota_media,\n",
    "  100.0 * SUM(CASE WHEN o.order_delivered_customer_date > o.order_estimated_delivery_date THEN 1 ELSE 0 END) \n",
    "    / COUNT(*) AS perc_atrasos\n",
    "FROM olist.default.orders o\n",
    "JOIN olist.default.order_reviews r ON o.order_id = r.order_id\n",
    "WHERE o.order_status = 'delivered'\n",
    "  AND o.order_delivered_customer_date IS NOT NULL\n",
    "  AND o.order_estimated_delivery_date IS NOT NULL\n",
    "GROUP BY safra\n",
    "ORDER BY safra\n",
    "\"\"\").toPandas()\n",
    "\n",
    "df_safra_avaliacoes['safra'] = pd.to_datetime(df_safra_avaliacoes['safra'])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "# Eixo Y esquerdo\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel(\"Safra (mês)\")\n",
    "ax1.set_ylabel(\"Nota média\", color=color)\n",
    "ax1.plot(df_safra_avaliacoes[\"safra\"], df_safra_avaliacoes[\"nota_media\"], color=color, marker='o', label='Nota média')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Eixo Y direito\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel(\"% atrasos\", color=color)\n",
    "ax2.plot(df_safra_avaliacoes[\"safra\"], df_safra_avaliacoes[\"perc_atrasos\"], color=color, marker='s', linestyle='--', label='% Atrasos')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper center\")\n",
    "\n",
    "plt.title(\"Nota média e Percentual de atrasos por safra\")\n",
    "fig.autofmt_xdate()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e7d172c-9b71-420a-aa06-3c91932528cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select \n",
    "  date_trunc('month', o.order_purchase_timestamp) as safra,\n",
    "  sum(oi.freight_value) as total_freight\n",
    "from olist.default.orders o\n",
    "left join olist.default.order_items oi \n",
    "  on o.order_id = oi.order_id\n",
    "where o.order_status = 'delivered' AND oi.freight_value is not null\n",
    "group by safra\n",
    "order by safra\n",
    "'''\n",
    "\n",
    "df = spark.sql(query).toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df['safra'], df['total_freight'], marker='s', color='darkorange')\n",
    "plt.title('Frete Total por safra')\n",
    "plt.xlabel('safra (mês)')\n",
    "plt.ylabel('Valor Total (R$)')\n",
    "plt.grid(axis='y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3210b98c-e355-4588-9714-325d734f00fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\n",
    "'''\n",
    "    select \n",
    "        date_trunc('month', o.order_purchase_timestamp) as safra,\n",
    "        count(distinct oi.order_id) as total_pedidos,\n",
    "        sum(oi.price) as total_valor_vendido,\n",
    "        total_valor_vendido/count(distinct oi.order_id) as ticket_medio,\n",
    "        sum(oi.freight_value) as total_valor_frete\n",
    "    from olist.default.order_items oi\n",
    "    join olist.default.orders o \n",
    "        on oi.order_id = o.order_id\n",
    "    where o.order_status = 'delivered'\n",
    "        and oi.price is not null\n",
    "    group by safra\n",
    "    order by safra\n",
    "'''\n",
    ").toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Y esquerdo\n",
    "color1 = 'tab:blue'\n",
    "ax1.set_xlabel('Safra (mês)')\n",
    "ax1.set_ylabel('Valor vendido (R$)', color=color1)\n",
    "line1, = ax1.plot(df['safra'], df['total_valor_vendido'], color=color1, marker='o', label='Total vendido')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "# Y direito\n",
    "ax2 = ax1.twinx()\n",
    "color2 = 'tab:green'\n",
    "ax2.set_ylabel('Valor arrecadado de frete (R$)', color=color2)\n",
    "line2, = ax2.plot(df['safra'], df['total_valor_frete'], color=color2, marker='s', linestyle='--', label='Total frete')\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "fig.suptitle('Valores arrecadados por safra')\n",
    "fig.autofmt_xdate()\n",
    "fig.tight_layout()\n",
    "ax1.legend(\n",
    "    [line1, line2], \n",
    "    [line.get_label() for line in [line1, line2]], \n",
    "    loc='upper left'\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc622b1a-24aa-4861-b923-398f3d63619f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    " select\n",
    "    date_trunc('month', o.order_purchase_timestamp) as safra,\n",
    "    avg(date_diff(o.order_delivered_customer_date, o.order_purchase_timestamp)) as tempo_medio_entrega,\n",
    "    avg(oi.freight_value) as valor_medio_frete\n",
    "from olist.default.orders o\n",
    "inner join olist.default.order_items oi\n",
    "on o.order_id = oi.order_id\n",
    "where o.order_status != 'canceled'\n",
    "    and o.order_status != 'unavailable'\n",
    "group by safra\n",
    "order by safra\n",
    "''').toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('safra (mês)')\n",
    "ax1.set_ylabel('Tempo Médio de Entrega (dias)', color=color)\n",
    "ax1.plot(df['safra'], df['tempo_medio_entrega'], marker='o', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(axis='y')\n",
    "ax1.grid(axis='x')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:orange'\n",
    "ax2.set_ylabel('Valor Médio de Frete (R$)', color=color)\n",
    "ax2.plot(df['safra'], df['valor_medio_frete'], marker='s', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid(axis='y')\n",
    "ax2.grid(axis='x')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.title('Tempo Médio de Entrega e Valor Médio de Frete por Safra')\n",
    "fig.legend(['Tempo Médio de Entrega', 'Valor Médio de Frete'], loc='center')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd92d87d-2f90-4d40-9730-1d827476a60a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Análise por Estado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "181fb7bc-8206-4766-936b-64337af5dba4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_valor_estado = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  c.customer_state,\n",
    "  SUM(oi.price) AS total_vendido\n",
    "FROM olist.default.orders o\n",
    "JOIN olist.default.customers c ON o.customer_id = c.customer_id\n",
    "JOIN olist.default.order_items oi ON o.order_id = oi.order_id\n",
    "WHERE o.order_status = 'delivered'\n",
    "GROUP BY c.customer_state\n",
    "ORDER BY total_vendido DESC\n",
    "\"\"\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(df_valor_estado['customer_state'], df_valor_estado['total_vendido'], color='mediumseagreen')\n",
    "plt.title(\"Valor total vendido por estado\")\n",
    "plt.ylabel(\"R$ total vendido\")\n",
    "plt.xlabel(\"Estado\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "263e919e-4747-4cde-9bb2-209e46d36bab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_estado = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  c.customer_state,\n",
    "  AVG(r.review_score) AS nota_media,\n",
    "  AVG(oi.price) AS ticket_medio\n",
    "FROM olist.default.orders o\n",
    "JOIN olist.default.customers c ON o.customer_id = c.customer_id\n",
    "JOIN olist.default.order_reviews r ON o.order_id = r.order_id\n",
    "JOIN olist.default.order_items oi ON o.order_id = oi.order_id\n",
    "WHERE o.order_status = 'delivered'\n",
    "GROUP BY c.customer_state\n",
    "ORDER BY ticket_medio DESC\n",
    "\"\"\").toPandas()\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Y esquerdo\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel(\"Estado\")\n",
    "ax1.set_ylabel(\"Nota média\", color=color)\n",
    "ax1.bar(df_estado[\"customer_state\"], df_estado[\"nota_media\"], color=color, alpha=0.6, label=\"Nota média\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Y direito\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel(\"Ticket médio (R$)\", color=color)\n",
    "ax2.plot(df_estado[\"customer_state\"], df_estado[\"ticket_medio\"], color=color, marker='o', label=\"Ticket médio\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper center\")\n",
    "\n",
    "plt.title(\"Nota média e Ticket médio por Estado\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0725be97-ed78-4644-a393-046347a1a673",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.customer_state,\n",
    "        count(*) as total_pedidos,\n",
    "        sum(CASE WHEN o.order_delivered_customer_date > o.order_estimated_delivery_date THEN 1 ELSE 0 END) as atrasos,\n",
    "        round(100* atrasos/total_pedidos, 2) as perc_atrasos\n",
    "    FROM olist.default.orders o\n",
    "    INNER JOIN olist.default.customers c\n",
    "    ON o.customer_id = c.customer_id\n",
    "    WHERE o.order_status = 'delivered'\n",
    "    AND o.order_delivered_customer_date IS NOT NULL\n",
    "    AND o.order_estimated_delivery_date IS NOT NULL\n",
    "    GROUP BY c.customer_state\n",
    "    HAVING COUNT(*) >= 500\n",
    "    ORDER BY perc_atrasos DESC\n",
    "\"\"\").toPandas()\n",
    "\n",
    "plt.Figure(figsize=(14, 10))\n",
    "sns.barplot(x='customer_state', y='perc_atrasos', data=df)\n",
    "plt.title('Percentual de Pedidos Atrasados por Estado')\n",
    "plt.xlabel('Estado')\n",
    "plt.ylabel('Percentual de Pedidos Atrasados (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c85c171-68a8-40c2-aeab-92811650fd75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    "select\n",
    "  c.customer_state as estado,\n",
    "  avg(oi.freight_value) as frete_medio\n",
    "from olist.default.customers c\n",
    "inner join olist.default.orders o \n",
    "  on c.customer_id = o.customer_id\n",
    "inner join olist.default.order_items oi\n",
    "  on o.order_id = oi.order_id\n",
    "where o.order_status != 'canceled' \n",
    "  and o.order_status != 'unavailable'\n",
    "group by estado\n",
    "order by frete_medio desc\n",
    "limit 10\n",
    "''').toPandas()\n",
    "\n",
    "plt.Figure(figsize=(14, 10))\n",
    "sns.barplot(x='estado', y='frete_medio', data=df)\n",
    "plt.title('Frete Médio por Estado')\n",
    "plt.xlabel('Estado')\n",
    "plt.ylabel('Frete Médio')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e4f8ceb-6d1a-4366-9617-35b8938ba86f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    "with base as (\n",
    "select\n",
    "  o.order_id as pedido,\n",
    "  case when o.order_delivered_customer_date > o.order_estimated_delivery_date then 1 else 0 end as atrasado\n",
    "from olist.default.orders o\n",
    "inner join olist.default.customers c\n",
    "  on o.customer_id = c.customer_id\n",
    "where c.customer_city = 'sao paulo'\n",
    "  and o.order_status = 'delivered'\n",
    "  and o.order_delivered_customer_date is not null\n",
    "  and o.order_estimated_delivery_date is not null\n",
    " )\n",
    "select\n",
    "  date_trunc('month', o.order_purchase_timestamp) as safra,\n",
    "  count(*) as total_pedidos,\n",
    "  sum(b.atrasado) as pedidos_atrasados,\n",
    "  round(100*pedidos_atrasados/total_pedidos, 2) as perc_atrasados\n",
    "from olist.default.orders o \n",
    "inner join base b \n",
    "  on o.order_id = b.pedido\n",
    "group by safra\n",
    "order by safra\n",
    "''').toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "plt.title('Percentual de Pedidos Atrasados por Safra -  Cidade Sao Paulo')\n",
    "plt.plot(df['safra'], df['perc_atrasados'], color='tab:blue', marker='o', label='Percentual de Pedidos Atrasados')\n",
    "plt.xlabel('Safra (mês)')\n",
    "plt.ylabel('Percentual de Pedidos Atrasados (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c013d35-57bc-4d27-b946-b913584a0f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_mapa_estado = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  c.customer_state,\n",
    "  COUNT(*) / COUNT(DISTINCT DATE_TRUNC('month', o.order_purchase_timestamp)) AS media_mensal_vendas\n",
    "FROM olist.default.orders o\n",
    "JOIN olist.default.customers c ON o.customer_id = c.customer_id\n",
    "WHERE o.order_status = 'delivered'\n",
    "GROUP BY c.customer_state\n",
    "\"\"\").toPandas()\n",
    "\n",
    "# Pegandod geoson do mapa do BR\n",
    "url = 'https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/brazil-states.geojson'\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    brasil_geo = json.load(response)\n",
    "\n",
    "# Mapear siglas para nomes compatíveis com o GeoJSON\n",
    "sigla_to_nome = {\n",
    "    'AC': 'Acre', 'AL': 'Alagoas', 'AP': 'Amapá', 'AM': 'Amazonas', 'BA': 'Bahia',\n",
    "    'CE': 'Ceará', 'DF': 'Distrito Federal', 'ES': 'Espírito Santo', 'GO': 'Goiás',\n",
    "    'MA': 'Maranhão', 'MT': 'Mato Grosso', 'MS': 'Mato Grosso do Sul', 'MG': 'Minas Gerais',\n",
    "    'PA': 'Pará', 'PB': 'Paraíba', 'PR': 'Paraná', 'PE': 'Pernambuco', 'PI': 'Piauí',\n",
    "    'RJ': 'Rio de Janeiro', 'RN': 'Rio Grande do Norte', 'RS': 'Rio Grande do Sul',\n",
    "    'RO': 'Rondônia', 'RR': 'Roraima', 'SC': 'Santa Catarina', 'SP': 'São Paulo',\n",
    "    'SE': 'Sergipe', 'TO': 'Tocantins'\n",
    "}\n",
    "\n",
    "df_mapa_estado['estado_nome'] = df_mapa_estado['customer_state'].map(sigla_to_nome)\n",
    "\n",
    "# Criar o mapa\n",
    "fig = px.choropleth(\n",
    "    df_mapa_estado,\n",
    "    geojson=brasil_geo,\n",
    "    featureidkey=\"properties.name\",  # chave do nome do estado no GeoJSON\n",
    "    locations=\"estado_nome\",\n",
    "    color=\"media_mensal_vendas\",\n",
    "    color_continuous_scale=\"Viridis\",\n",
    "    scope=\"south america\",\n",
    "    title=\"Volume médio mensal de vendas por estado (Brasil)\",\n",
    "    labels={\"media_mensal_vendas\": \"Média mensal de vendas\"}\n",
    ")\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":50,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "441f08a4-855d-4019-a1cd-a62df3015383",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Análise por Sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d88ab0-9421-4162-87f8-783eab7c9791",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top10_df = spark.sql(\"\"\"\n",
    "SELECT seller_id\n",
    "FROM (\n",
    "  SELECT \n",
    "    seller_id,\n",
    "    COUNT(DISTINCT order_id) AS total_pedidos\n",
    "  FROM olist.default.order_items\n",
    "  GROUP BY seller_id\n",
    ")\n",
    "ORDER BY total_pedidos DESC\n",
    "LIMIT 4\n",
    "\"\"\").toPandas()\n",
    "\n",
    "top10_ids = top10_df['seller_id'].tolist()\n",
    "\n",
    "# Pegar as vendas desses sellers\n",
    "vendas_top10 = spark.sql(f\"\"\"\n",
    "SELECT \n",
    "  DATE_TRUNC('month', o.order_purchase_timestamp) AS safra,\n",
    "  oi.seller_id,\n",
    "  COUNT(DISTINCT oi.order_id) AS qtd_pedidos,\n",
    "  SUM(oi.price) AS valor_total\n",
    "FROM \n",
    "  olist.default.order_items oi\n",
    "JOIN \n",
    "  olist.default.orders o\n",
    "ON \n",
    "  oi.order_id = o.order_id\n",
    "WHERE \n",
    "  o.order_status = 'delivered'\n",
    "  AND seller_id IN ({','.join([f\"'{s}'\" for s in top10_ids])})\n",
    "GROUP BY \n",
    "  seller_id, DATE_TRUNC('month', o.order_purchase_timestamp)\n",
    "\"\"\").toPandas()\n",
    "\n",
    "vendas_top10['safra'] = pd.to_datetime(vendas_top10['safra'])\n",
    "\n",
    "vendas_top10 = vendas_top10.sort_values(['seller_id', 'safra'])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for seller in top10_ids:\n",
    "    data = vendas_top10[vendas_top10['seller_id'] == seller]\n",
    "    plt.plot(data['safra'], data['qtd_pedidos'], marker='o', label=f'{seller[:6]}...')\n",
    "\n",
    "plt.title('Quantidade de pedidos por safra - Top Sellers')\n",
    "plt.xlabel('Safra (mês)')\n",
    "plt.ylabel('Qtd pedidos')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for seller in top10_ids:\n",
    "    data = vendas_top10[vendas_top10['seller_id'] == seller]\n",
    "    plt.plot(data['safra'], data['valor_total'], marker='s', linestyle='--', label=f'{seller[:6]}...')\n",
    "\n",
    "plt.title('Valor total vendido por safra (R$) - Top Sellers')\n",
    "plt.xlabel('Safra (mês)')\n",
    "plt.ylabel('Valor vendido (R$)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c8399c-e2df-4df8-888f-22b57ff7f035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top4_sellers = spark.sql('''\n",
    "    select seller_id \n",
    "    from (\n",
    "        select\n",
    "        seller_id,\n",
    "        count(distinct order_id) as total_pedidos\n",
    "        from olist.default.order_items\n",
    "        group by seller_id\n",
    "        order by total_pedidos desc\n",
    "        limit 4\n",
    "    )\n",
    "'''\n",
    ").toPandas()\n",
    "\n",
    "lista_sellers = \",\".join([f\"'{s}'\" for s in top4_sellers['seller_id']])\n",
    "\n",
    "df = spark.sql(\n",
    "    f'''\n",
    "    select \n",
    "      date_trunc('month', o.order_purchase_timestamp) as safra,\n",
    "      oi.seller_id,\n",
    "      sum(oi.freight_value) as total_freight\n",
    "    from olist.default.orders o\n",
    "    left join olist.default.order_items oi\n",
    "        on o.order_id = oi.order_id\n",
    "    where o.order_status = 'delivered' \n",
    "        and oi.seller_id in ({lista_sellers})\n",
    "        and oi.freight_value is not null\n",
    "    group by safra, oi.seller_id\n",
    "    order by safra\n",
    "    '''\n",
    ").toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "seller_ids = df.seller_id.unique()\n",
    "seller_labels = {id: f'seller_{chr(65+i)}' for i, id in enumerate(seller_ids)}\n",
    "df['seller_label'] = df['seller_id'].map(seller_labels)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "for seller in df['seller_label'].unique():\n",
    "    dados = df[df.seller_label == seller]\n",
    "    plt.plot(dados['safra'], dados['total_freight'], label=seller)\n",
    "\n",
    "plt.title('Frete total arrecadado por safra (R$) - Top4 Sellers')\n",
    "plt.xlabel('Safra (mês)')\n",
    "plt.ylabel('Frete Arrecadado (R$)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91005640-efe7-416e-a8e6-6ae365c4f02b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_seller = spark.sql(\"\"\"\n",
    "WITH vendas_por_seller AS (\n",
    "  SELECT \n",
    "    oi.seller_id,\n",
    "    AVG(r.review_score) AS nota_media,\n",
    "    AVG(oi.price) AS ticket_medio\n",
    "  FROM olist.default.order_items oi\n",
    "  JOIN olist.default.orders o ON oi.order_id = o.order_id\n",
    "  JOIN olist.default.order_reviews r ON o.order_id = r.order_id\n",
    "  WHERE o.order_status = 'delivered'\n",
    "  GROUP BY oi.seller_id\n",
    "),\n",
    "top4 AS (\n",
    "  SELECT seller_id\n",
    "  FROM olist.default.order_items\n",
    "  GROUP BY seller_id\n",
    "  ORDER BY COUNT(*) DESC\n",
    "  LIMIT 4\n",
    ")\n",
    "SELECT v.*\n",
    "FROM vendas_por_seller v\n",
    "JOIN top4 t ON v.seller_id = t.seller_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "df_seller = df_seller.copy()\n",
    "df_seller['seller_label'] = ['Seller A', 'Seller B', 'Seller C', 'Seller D']\n",
    "\n",
    "x = np.arange(len(df_seller))\n",
    "width = 0.35  # Largura das barras\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "bars1 = ax.bar(x - width/2, df_seller['nota_media'], width, label='Nota média', color='cornflowerblue')\n",
    "bars2 = ax.bar(x + width/2, df_seller['ticket_medio'], width, label='Ticket médio (R$)', color='mediumseagreen')\n",
    "\n",
    "ax.set_xlabel('Seller')\n",
    "ax.set_title('Nota média e Ticket médio por Seller (Top 4)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_seller['seller_label'])\n",
    "ax.legend()\n",
    "ax.grid(axis='y')\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.1f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=9, color='blue')\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'R${height:.0f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=9, color='green')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c14a551-75df-4342-b0d6-d2d8f557d2ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_atraso_nota_seller = spark.sql(\"\"\"\n",
    "WITH sellers_top10 AS (\n",
    "  SELECT seller_id\n",
    "  FROM olist.default.order_items\n",
    "  GROUP BY seller_id\n",
    "  ORDER BY COUNT(DISTINCT order_id) DESC\n",
    "  LIMIT 10\n",
    "),\n",
    "base AS (\n",
    "  SELECT \n",
    "    oi.seller_id,\n",
    "    o.order_id,\n",
    "    r.review_score,\n",
    "    CASE \n",
    "      WHEN o.order_delivered_customer_date > o.order_estimated_delivery_date THEN 1 \n",
    "      ELSE 0 \n",
    "    END AS atraso\n",
    "  FROM olist.default.order_items oi\n",
    "  JOIN olist.default.orders o ON oi.order_id = o.order_id\n",
    "  JOIN olist.default.order_reviews r ON o.order_id = r.order_id\n",
    "  WHERE o.order_status = 'delivered'\n",
    "    AND o.order_delivered_customer_date IS NOT NULL\n",
    "    AND o.order_estimated_delivery_date IS NOT NULL\n",
    "    AND oi.seller_id IN (\n",
    "      SELECT seller_id FROM sellers_top10\n",
    "    )\n",
    ")\n",
    "SELECT \n",
    "  seller_id,\n",
    "  AVG(review_score) AS nota_media,\n",
    "  100.0 * SUM(atraso) / COUNT(*) AS perc_atrasos\n",
    "FROM base\n",
    "GROUP BY seller_id\n",
    "\"\"\").toPandas()\n",
    "\n",
    "# Label mais legíveis pros sellers\n",
    "df_atraso_nota_seller['seller_label'] = ['Seller ' + chr(65+i) for i in range(len(df_atraso_nota_seller))]\n",
    "\n",
    "x = np.arange(len(df_atraso_nota_seller))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "bars1 = ax.bar(x - width/2, df_atraso_nota_seller['nota_media'], width, label='Nota média', color='cornflowerblue')\n",
    "bars2 = ax.bar(x + width/2, df_atraso_nota_seller['perc_atrasos'], width, label='% atrasos', color='darkorange')\n",
    "\n",
    "ax.set_xlabel('Seller')\n",
    "ax.set_title('Nota média e Percentual de Atrasos (Top 10 Sellers)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_atraso_nota_seller['seller_label'])\n",
    "ax.legend()\n",
    "ax.grid(axis='y')\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.1f}%',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=9, color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eeac8557-72bb-4914-947a-1c0add09f51d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Anáĺise Categorias de Prdutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed99c645-fcb9-4ab8-a5f7-cb485f217c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_top_categorias = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  p.product_category_name,\n",
    "  COUNT(*) AS total_vendas\n",
    "FROM olist.default.order_items oi\n",
    "JOIN olist.default.products p ON oi.product_id = p.product_id\n",
    "JOIN olist.default.orders o ON oi.order_id = o.order_id\n",
    "WHERE o.order_status = 'delivered'\n",
    "GROUP BY p.product_category_name\n",
    "ORDER BY total_vendas DESC\n",
    "LIMIT 10\n",
    "\"\"\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x='product_category_name', y='total_vendas', data=df_top_categorias)\n",
    "plt.title(\"Top 10 categorias de produto mais vendidas\")\n",
    "plt.ylabel(\"Total de vendas\")\n",
    "plt.xlabel(\"Categoria\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c18317f1-5b58-4ed1-9a7f-cf0e23275277",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top10_categorias = df_top_categorias['product_category_name'].tolist()\n",
    "\n",
    "# Convertendo para string SQL\n",
    "categorias_sql = ','.join([f\"'{c}'\" for c in top10_categorias])\n",
    "\n",
    "df_categorias_safra = spark.sql(f\"\"\"\n",
    "SELECT \n",
    "  DATE_TRUNC('month', o.order_purchase_timestamp) AS safra,\n",
    "  p.product_category_name,\n",
    "  COUNT(*) AS qtd_vendas\n",
    "FROM olist.default.order_items oi\n",
    "JOIN olist.default.products p ON oi.product_id = p.product_id\n",
    "JOIN olist.default.orders o ON oi.order_id = o.order_id\n",
    "WHERE o.order_status = 'delivered'\n",
    "  AND p.product_category_name IN ({categorias_sql})\n",
    "GROUP BY safra, p.product_category_name\n",
    "ORDER BY safra\n",
    "\"\"\").toPandas()\n",
    "\n",
    "df_categorias_safra['safra'] = pd.to_datetime(df_categorias_safra['safra'])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for categoria in top10_categorias:\n",
    "    dados = df_categorias_safra[df_categorias_safra['product_category_name'] == categoria]\n",
    "    plt.plot(dados['safra'], dados['qtd_vendas'], label=categoria)\n",
    "\n",
    "plt.title('Curva de vendas por safra - Top 10 categorias')\n",
    "plt.xlabel('Safra (mês)')\n",
    "plt.ylabel('Quantidade de vendas')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d60e3b-5dde-49f5-a608-d2479d737b5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    "with info as (\n",
    "select\n",
    "    oi.product_id as produto,\n",
    "    orv.review_score as nota\n",
    "from olist.default.orders o\n",
    "inner join olist.default.order_items oi \n",
    "    on o.order_id = oi.order_id\n",
    "inner join olist.default.order_reviews orv \n",
    "    on o.order_id = orv.order_id\n",
    "where o.order_status != 'canceled' \n",
    "    and o.order_status != 'unavailable'\n",
    ")\n",
    "select\n",
    "    p.product_category_name as categoria,\n",
    "    avg(nota) as nota_media\n",
    "from olist.default.products p\n",
    "inner join info i\n",
    "    on p.product_id = i.produto\n",
    "group by categoria\n",
    "order by nota_media desc\n",
    "limit 10\n",
    "''').toPandas()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(x='categoria', y='nota_media', data=df)\n",
    "plt.title('Top10 Categorias com Maior Nota Média')\n",
    "plt.xticks(rotation=75)\n",
    "plt.xlabel('Categoria')\n",
    "plt.ylabel('Nota Média')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d907dff-56ff-45bf-8a33-592dbf49d1d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    "    select\n",
    "        p.product_category_name as categoria,\n",
    "        count(o.order_id) as qtd_pedidos,\n",
    "        sum(case when (o.order_delivered_customer_date > o.order_estimated_delivery_date) then 1 else 0 end) as total_atrasados,\n",
    "        round(100*total_atrasados/qtd_pedidos, 2) as perc_atrasados\n",
    "    from olist.default.order_items oi\n",
    "    inner join olist.default.orders o\n",
    "        on oi.order_id = o.order_id\n",
    "    inner join olist.default.products p\n",
    "        on oi.product_id = p.product_id\n",
    "    where o.order_status = 'delivered'\n",
    "        and o.order_delivered_customer_date is not null\n",
    "        and o.order_estimated_delivery_date is not null\n",
    "        and p.product_category_name is not null\n",
    "    group by p.product_category_name\n",
    "    order by perc_atrasados desc\n",
    "    limit 10               \n",
    "''').toPandas()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(x='categoria', y='perc_atrasados', data=df)\n",
    "plt.title('Top10 Categorias com Maior Percentual de Pedidos Atrasados')\n",
    "plt.xlabel('Categoria')\n",
    "plt.ylabel('Percentual de Pedidos Atrasados (%)')\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5a56ce0-c51e-4223-b076-b2af8666b553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    "select\n",
    "  p.product_category_name as categoria,\n",
    "  avg(oi.freight_value) as media_frete\n",
    "from olist.default.order_items oi\n",
    "inner join olist.default.products p\n",
    "  on p.product_id = oi.product_id\n",
    "group by p.product_category_name\n",
    "order by media_frete desc\n",
    "limit 10\n",
    "''').toPandas()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(x='categoria', y='media_frete', data=df)\n",
    "plt.title('Top10 Categorias Fretes Mais Caros')\n",
    "plt.xlabel('Categoria')\n",
    "plt.ylabel('Média de Frete')\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31b2dfcb-9b05-469b-8163-98531f103549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    "select\n",
    "  p.product_category_name as produto,\n",
    "  avg(oi.price) as preco_medio\n",
    "from olist.default.orders o\n",
    "inner join olist.default.order_items oi\n",
    "  on o.order_id = oi.order_id\n",
    "inner join olist.default.products p\n",
    "  on oi.product_id = p.product_id\n",
    "where o.order_status != 'canceled'\n",
    "  and o.order_status != 'unavailable'\n",
    "group by p.product_category_name\n",
    "order by preco_medio desc\n",
    "limit 10\n",
    "''').toPandas()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.barplot(x='produto', y='preco_medio', data=df)\n",
    "plt.title('Top10 Categorias mais Caras')\n",
    "plt.xlabel('Categoria')\n",
    "plt.ylabel('Preço Médio (R$)')\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff134ee7-802c-4952-8514-07b134d516f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    "with vendas as (\n",
    "select\n",
    "    date_trunc('month', o.order_purchase_timestamp) as safra,\n",
    "    o.order_id as pedido,\n",
    "    oi.product_id as produto,\n",
    "    case when o.order_delivered_customer_date > o.order_estimated_delivery_date then 1 else 0 end as atrasado\n",
    "from olist.default.orders o\n",
    "inner join olist.default.order_items oi\n",
    "    on o.order_id = oi.order_id\n",
    "where o.order_status != 'canceled'\n",
    "    and o.order_status != 'unavailable'\n",
    "    and o.order_delivered_customer_date is not null\n",
    ")\n",
    "select\n",
    "    v.safra as safra,\n",
    "    count(v.pedido) as qtd_pedidos,\n",
    "    sum(v.atrasado) as qtd_atrasados,\n",
    "    round(qtd_atrasados/qtd_pedidos, 2) as perc_atrasados\n",
    "from olist.default.products p\n",
    "inner join vendas v\n",
    "    on p.product_id = v.produto\n",
    "inner join olist.default.order_reviews orv\n",
    "    on v.pedido = orv.order_id\n",
    "where p.product_category_name = 'cama_mesa_banho'\n",
    "group by v.safra\n",
    "order by v.safra               \n",
    "''').toPandas()\n",
    "\n",
    "df['safra'] = pd.to_datetime(df['safra'])\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df['safra'], df['perc_atrasados'], label='Cama Mesa e Banho')\n",
    "plt.title('Percentual de Pedidos Atrasados por Safra para Cama Mesa e Banho')\n",
    "plt.xlabel('Safra')\n",
    "plt.ylabel('Percentual de Pedidos Atrasados (%)')\n",
    "plt.grid(axis='y')\n",
    "plt.grid(axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "explorando_datasets",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
